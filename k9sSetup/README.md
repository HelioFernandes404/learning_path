# K9s Multi-Context Manager

Gerenciador de mÃºltiplos clusters Kubernetes com tÃºneis SSH seguros.

---

## ğŸš€ Quick Start

```bash
# 1. Ver todos os comandos disponÃ­veis
make help

# 2. Setup inicial (primeira vez)
make init

# 3. (Opcional) Customizar config
make config
# ou edite: ~/.k9s-config/config.yaml
# Docs: docs/CONFIG.md

# 4a. Conectar a um Ãºnico cluster
make run

# 4b. Conectar a mÃºltiplos clusters simultaneamente (NOVO!)
make multi-connect

# 5. Abrir k9s
make k9s

# 6. Ver status de todos os clusters conectados
make status
```

### Modo Tradicional (sem Makefile)

```bash
./init.sh
source venv/bin/activate

# Um cluster
python3 fetch_k3s_config.py

# MÃºltiplos clusters
python3 multi_connect.py

# Abrir k9s
./k9s-with-tunnel.sh
```

---

## âš™ï¸ Configuration

### Default Config (Auto-created by `init.sh`)

**Location:** `~/.k9s-config/config.yaml`

**Default values:**
```yaml
remote_k3s_config_path: /etc/rancher/k3s/k3s.yaml
ssh_key_path: ~/.ssh/id_ed25519
k3s_api_port: 6443
port_range_start: 16443
port_range_size: 10000
```

### Environment Variable Overrides

```bash
# Use custom K3s port for specific cluster
export K3S_API_PORT=7443
python3 fetch_k3s_config.py

# Use larger port range for many clusters
export PORT_RANGE_START=10000
export PORT_RANGE_SIZE=50000
python3 fetch_k3s_config.py

# Enable file logging
export K9S_LOG_FILE=~/.local/state/k9s/k9s-config.log
python3 fetch_k3s_config.py
```

**Full documentation:** See [docs/CONFIG.md](docs/CONFIG.md)

---

## ğŸ“– Guia Completo

### 1ï¸âƒ£ Primeira Vez: Setup

```bash
# Clonar (se ainda nÃ£o tiver)
git clone https://github.com/HelioFernandes404/k9s-config.git
cd k9s-config

# Rodar setup automÃ¡tico
./init.sh
```

Isso cria o ambiente virtual e instala dependÃªncias.

### 2ï¸âƒ£ Adicionar Novo Cluster

```bash
# Ativar ambiente
source venv/bin/activate

# Executar script
python3 fetch_k3s_config.py
```

**O script pergunta:**
1. Qual empresa? (lista do `inventory/`)
2. Qual host? (mostra `[VPN]` se necessÃ¡rio)

**O script faz:**
- âœ… Conecta via SSH
- âœ… Busca kubeconfig do K3s
- âœ… Cria tÃºnel SSH seguro
- âœ… Adiciona contexto no `~/.kube/config`

**SaÃ­da esperada:**
```
âœ“ Context 'empresa-host' added to ~/.kube/config
âœ“ Set as current context
âœ“ SSH tunnel created (PID: 123456)

You can now use kubectl/k9s directly!
  kubectl get nodes
  k9s -l debug
```

### 3ï¸âƒ£ Abrir K9s

```bash
./k9s-with-tunnel.sh
```

Isso verifica se o tÃºnel estÃ¡ ativo e abre k9s em modo debug.

**Logs:** `tail -f ~/.local/state/k9s/k9s.log`

---

## ğŸ”„ MÃºltiplos Clusters SimultÃ¢neos (NOVO!)

### Conectar a mÃºltiplos clusters de uma vez

```bash
make multi-connect
```

**O que acontece:**
1. ğŸ“‹ Mostra lista de todos os clusters disponÃ­veis com checkboxes
2. âœ… Selecione mÃºltiplos clusters (espaÃ§o para marcar, enter para confirmar)
3. âš ï¸ Mostra avisos de VPN/sshuttle se necessÃ¡rio
4. ğŸ”— Conecta a cada cluster sequencialmente
5. ğŸ¯ Define o primeiro cluster selecionado como ativo

**Exemplo de uso:**
```
Select clusters to connect (space to select, enter to confirm):
[x] hostinger: vps-prod
[x] primaria: prod-k3s [sshuttle]
[ ] cogcs: cogcs-server

âœ“ Connected: 2/2 clusters
  âœ“ hostinger-vps-prod (localhost:16443)
  âœ“ primaria-prod-k3s (localhost:17891) âš  requires sshuttle

âš  Active network requirements:
  ğŸ”’ sshuttle -v -r helio@100.64.5.10 192.168.90.0/24

Active context: hostinger-vps-prod
```

### Trocar entre clusters conectados

```bash
# Ver status de todos os clusters
make status

# Trocar contexto
kubectl config use-context empresa-host

# Abrir k9s (validaÃ§Ã£o automÃ¡tica de rede)
make k9s
```

### Adicionar mais um cluster

Se vocÃª jÃ¡ tem alguns clusters conectados e quer adicionar mais um:

```bash
# Adicionar um Ãºnico cluster
make run

# Ou reconectar mÃºltiplos
make multi-connect
```

---

## ğŸ› ï¸ Comandos Ãšteis

### Ver Status de Clusters

```bash
# Ver todos os clusters conectados com seus tÃºneis
make status
```

**Output:**
```
Connected clusters:
  âœ“ hostinger-vps-prod (localhost:16443) [PID: 12345]
  âœ“ primaria-prod-k3s (localhost:17891) [PID: 12346] âš  requires sshuttle
  âœ— cogcs-cogcs (tunnel down)

Current context: hostinger-vps-prod

Active network requirements:
  ğŸ”’ sshuttle -v -r helio@100.64.5.10 192.168.90.0/24
```

### Gerenciar TÃºneis

```bash
# Ver tÃºneis ativos
make tunnel-list

# Matar tÃºnel especÃ­fico
make tunnel-kill CONTEXT=empresa-host

# Matar todos
make tunnel-kill-all
```

**Modo tradicional:**
```bash
./k9s-with-tunnel.sh list
./k9s-with-tunnel.sh kill empresa-host
./k9s-with-tunnel.sh kill-all
```

### Gerenciar Contextos

```bash
# Ver contextos
kubectl config get-contexts

# Ver contexto atual
kubectl config current-context

# Trocar contexto
kubectl config use-context empresa-host

# Deletar contexto
kubectl config delete-context empresa-host
```

---

## ğŸ“ Estrutura

```
k9s-config/
â”œâ”€â”€ Makefile                  # Interface principal (use make help)
â”œâ”€â”€ fetch_k3s_config.py       # Conectar cluster Ãºnico
â”œâ”€â”€ multi_connect.py          # Conectar mÃºltiplos clusters (NOVO!)
â”œâ”€â”€ k9s-with-tunnel.sh        # Helper k9s + tÃºneis + validaÃ§Ã£o de rede
â”œâ”€â”€ init.sh                   # Setup venv
â”œâ”€â”€ inventory/                # InventÃ¡rios (Ansible-style)
â”‚   â”œâ”€â”€ empresa_hosts.yml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                      # MÃ³dulos Python
â”‚   â”œâ”€â”€ inventory.py
â”‚   â”œâ”€â”€ ssh.py
â”‚   â”œâ”€â”€ tunnel.py
â”‚   â”œâ”€â”€ network_validator.py  # ValidaÃ§Ã£o VPN/sshuttle (NOVO!)
â”‚   â”œâ”€â”€ multi_status.py       # Status multi-cluster (NOVO!)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ venv/                     # Ambiente Python
â””â”€â”€ README.md                 # Este arquivo
```

**Estado persistente:**
```
~/.local/state/k9s-tunnels/
â”œâ”€â”€ empresa-host.pid          # PID do tÃºnel SSH
â””â”€â”€ empresa-host.network      # Metadados de rede (VPN/sshuttle)
```

---

## ğŸ¢ Adicionar Nova Empresa

### Criar inventÃ¡rio: `inventory/empresa_hosts.yml`

```yaml
all:
  vars:
    customer: empresa
    ansible_user: ubuntu

  children:
    k3s_cluster:
      vars:
        # argocd_use_socks5_proxy: true  # Se precisar VPN
      hosts:
        meu-servidor:
          ansible_host: 192.168.1.100
```

### Configurar SSH: `~/.ssh/config`

```
Host meu-servidor
  HostName 192.168.1.100
  User ubuntu
  IdentityFile ~/.ssh/chave
```

### Executar

```bash
make add-cluster
# ou: source venv/bin/activate && python3 fetch_k3s_config.py
```

---

## ğŸ”’ SeguranÃ§a

- âœ… TÃºneis SSH (nÃ£o expÃµe K3s na internet)
- âœ… Porta Ãºnica por cluster
- âœ… InventÃ¡rios nÃ£o versionados (`.gitignore`)
- âœ… Backup automÃ¡tico de configs

---

## ğŸ› Troubleshooting

### "No tunnel found"
```bash
# Ver tÃºneis
./k9s-with-tunnel.sh list

# Recriar
source venv/bin/activate
python3 fetch_k3s_config.py
```

### "Connection refused"
```bash
# Verificar SSH
ssh <host> 'systemctl status k3s'

# Verificar tÃºnel
./k9s-with-tunnel.sh list

# Recriar contexto
python3 fetch_k3s_config.py
```

### Limpar tudo
```bash
./k9s-with-tunnel.sh kill-all
kubectl config delete-context <nome>
python3 fetch_k3s_config.py
```

---

## ğŸ’¡ Workflow TÃ­pico

```bash
# Dia 1: Setup
./init.sh
source venv/bin/activate
python3 fetch_k3s_config.py  # Adicionar cluster A

# Trabalhar no cluster A
./k9s-with-tunnel.sh

# Adicionar cluster B
python3 fetch_k3s_config.py

# Trabalhar no cluster B
./k9s-with-tunnel.sh

# Voltar para A
kubectl config use-context empresa-A
./k9s-with-tunnel.sh
```

---

## ğŸ“ Onde Buscar Ajuda

- **Logs do fetch**: SaÃ­da do `python3 fetch_k3s_config.py`
- **Logs do k9s**: `tail -f ~/.local/state/k9s/k9s.log`
- **TÃºneis**: `ls ~/.local/state/k9s-tunnels/`
- **Kubeconfig**: `cat ~/.kube/config`

---

**Desenvolvido com â¤ï¸ para gerenciar mÃºltiplos clusters K3s de forma segura**
